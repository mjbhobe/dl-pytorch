{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature prediction using LSTM in Pytorch\n",
    "In this notebook we'll explore how to use a LSTM to predict temperature from weather data using a Pytorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch 2.1.2+rocm5.6. GPU is not available :(\n",
      "Will train models on cpu\n",
      "Model state will be saved to /home/mjbhobe/code/git-projects/dl-pytorch/model_states\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "\n",
    "if sys.version_info < (3,):\n",
    "    raise Exception(\n",
    "        \"pytorch_toolkit does not support Python 2. Please use a Python 3+ interpreter!\"\n",
    "    )\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchsummary as ts\n",
    "import torch_training_toolkit as t3\n",
    "\n",
    "SEED = 41\n",
    "t3.seed_all(SEED)\n",
    "\n",
    "# tweaking libraries\n",
    "plt.rcParams[\"figure.figsize\"] = (5, 4)\n",
    "np.set_printoptions(suppress=True, precision=3, linewidth=110)\n",
    "pd.set_option(\"display.float_format\", \"{:,.3f}\".format)\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Using Pytorch {torch.__version__}. GPU {'is available :)' if torch.cuda.is_available() else 'is not available :('}\"\n",
    ")\n",
    "DEVICE = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else (\"dml\" if (hasattr(torch, \"dml\") and torch.dml.is_available()) else \"cpu\")\n",
    ")\n",
    "print(f\"Will train models on {DEVICE}\")\n",
    "\n",
    "MODEL_SAVE_DIR = pathlib.Path(os.getcwd()) / \"model_states\"\n",
    "print(f\"Model state will be saved to {MODEL_SAVE_DIR}\")\n",
    "DATA_DIR = pathlib.Path(os.getcwd()) / \"csv_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981-01-01</th>\n",
       "      <td>20.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-02</th>\n",
       "      <td>17.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-03</th>\n",
       "      <td>18.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-04</th>\n",
       "      <td>14.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-05</th>\n",
       "      <td>15.800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Temp\n",
       "Date             \n",
       "1981-01-01 20.700\n",
       "1981-01-02 17.900\n",
       "1981-01-03 18.800\n",
       "1981-01-04 14.600\n",
       "1981-01-05 15.800"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data from URL\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "url = \"https://github.com/jbrownlee/Datasets/blob/master/daily-min-temperatures.csv\"\n",
    "target_file_name = DATA_DIR / \"daily-min-temperatures.csv\"\n",
    "if not os.path.exists(target_file_name):\n",
    "    # download only if necessary\n",
    "    urlretrieve(url, target_file_name)\n",
    "    assert os.path.exists(\n",
    "        target_file_name\n",
    "    ), f\"FATAL ERROR: unable to download to {target_file_name}\"\n",
    "# open data file\n",
    "df = pd.read_csv(target_file_name, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981-01-01</th>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-02</th>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-03</th>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-04</th>\n",
       "      <td>0.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-05</th>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Temp\n",
       "Date            \n",
       "1981-01-01 0.787\n",
       "1981-01-02 0.681\n",
       "1981-01-03 0.715\n",
       "1981-01-04 0.555\n",
       "1981-01-05 0.601"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[\"Temp\"] = scaler.fit_transform(df[[\"Temp\"]])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.787, 0.681, 0.715, 0.555, 0.601, 0.601, 0.601, 0.662, 0.829, 0.76 , 0.616]), array([0.681, 0.715, 0.555, 0.601, 0.601, 0.601, 0.662, 0.829, 0.76 , 0.616, 0.506]), array([0.715, 0.555, 0.601, 0.601, 0.601, 0.662, 0.829, 0.76 , 0.616, 0.506, 0.635]), array([0.555, 0.601, 0.601, 0.601, 0.662, 0.829, 0.76 , 0.616, 0.506, 0.635, 0.817]), array([0.601, 0.601, 0.601, 0.662, 0.829, 0.76 , 0.616, 0.506, 0.635, 0.817, 0.951]), array([0.601, 0.601, 0.662, 0.829, 0.76 , 0.616, 0.506, 0.635, 0.817, 0.951, 0.787]), array([0.601, 0.662, 0.829, 0.76 , 0.616, 0.506, 0.635, 0.817, 0.951, 0.787, 0.783]), array([0.662, 0.829, 0.76 , 0.616, 0.506, 0.635, 0.817, 0.951, 0.787, 0.783, 0.943]), array([0.829, 0.76 , 0.616, 0.506, 0.635, 0.817, 0.951, 0.787, 0.783, 0.943, 0.673]), array([0.76 , 0.616, 0.506, 0.635, 0.817, 0.951, 0.787, 0.783, 0.943, 0.673, 0.589]), array([0.616, 0.506, 0.635, 0.817, 0.951, 0.787, 0.783, 0.943, 0.673, 0.589, 0.692]), array([0.506, 0.635, 0.817, 0.951, 0.787, 0.783, 0.943, 0.673, 0.589, 0.692, 0.46 ]), array([0.635, 0.817, 0.951, 0.787, 0.783, 0.943, 0.673, 0.589, 0.692, 0.46 , 0.548]), array([0.817, 0.951, 0.787, 0.783, 0.943, 0.673, 0.589, 0.692, 0.46 , 0.548, 0.608]), array([0.951, 0.787, 0.783, 0.943, 0.673, 0.589, 0.692, 0.46 , 0.548, 0.608, 0.627]), array([0.787, 0.783, 0.943, 0.673, 0.589, 0.692, 0.46 , 0.548, 0.608, 0.627, 0.711]), array([0.783, 0.943, 0.673, 0.589, 0.692, 0.46 , 0.548, 0.608, 0.627, 0.711, 0.738]), array([0.943, 0.673, 0.589, 0.692, 0.46 , 0.548, 0.608, 0.627, 0.711, 0.738, 0.654]), array([0.673, 0.589, 0.692, 0.46 , 0.548, 0.608, 0.627, 0.711, 0.738, 0.654, 0.589]), array([0.589, 0.692, 0.46 , 0.548, 0.608, 0.627, 0.711, 0.738, 0.654, 0.589, 0.574])]\n"
     ]
    }
   ],
   "source": [
    "# prepare sequences using a 10 row window\n",
    "sequence_length = 10\n",
    "sequences = []\n",
    "for i in range(len(df) - sequence_length):\n",
    "    # grad data from indexes 0-10, 1-11, 2-12...\n",
    "    seq = df[\"Temp\"].iloc[i : i + sequence_length + 1].values\n",
    "    sequences.append(seq)\n",
    "print(sequences[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3640 3640\n"
     ]
    }
   ],
   "source": [
    "# for each of the list in the sequence above, the first sequence_length - 1 elements is the data\n",
    "# and the last item is the target\n",
    "X, y = [seq[:-1] for seq in sequences], [seq[-1] for seq in sequences]\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (2912, 10, 1) - y_train.shap: (2912,) - X_test.shape: (728, 10, 1) - y_test.shape: (728,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# an LSTM expects input sequences in the shape (batch_size, time_steps, num_features)\n",
    "X_train = np.array(X_train).reshape(len(X_train), sequence_length, 1)\n",
    "X_test = np.array(X_test).reshape(len(X_test), sequence_length, 1)\n",
    "y_train, y_test = np.array(y_train), np.array(y_test)\n",
    "print(\n",
    "    f\"X_train.shape: {X_train.shape} - y_train.shap: {y_train.shape} - \"\n",
    "    f\"X_test.shape: {X_test.shape} - y_test.shape: {y_test.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1, num_layers=2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # define the layers of LSTM\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True)\n",
    "        # output layer\n",
    "        self.linear = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # this is called in the training loop\n",
    "        return (\n",
    "            torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "            torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        # forward pass through the network\n",
    "        out, self.hidden = self.lstm(\n",
    "            input.view(len(input), self.batch_size, -1), self.hidden\n",
    "        )\n",
    "        # take the last step from out\n",
    "        out = self.linear(out[-1].view(self.batch_size, -1))\n",
    "        return out.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "input_dim, hidden_dim, batch_size = 1, 64, 16\n",
    "model = LSTMModel(input_dim=input_dim, hidden_dim=hidden_dim, batch_size=batch_size)\n",
    "loss_fxn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx = torch.tensor(X_train[0:batch_size])\n",
    "bx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# compute loss\u001b[39;00m\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fxn(y_pred, batch_y)\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1395\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1373\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "num_epochs = 100\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    losses = np.array([])\n",
    "    num_batches = len(X_train) // batch_size\n",
    "    for i in range(num_batches):\n",
    "        batch_X = torch.tensor(X_train[i * batch_size : (i + 1) * batch_size])\n",
    "        batch_X = batch_X.to(DEVICE)\n",
    "        batch_y = torch.tensor(y_train[i * batch_size : (i + 1) * batch_size])\n",
    "        batch_y = batch_y.to(DEVICE)\n",
    "        # initialize hidden state\n",
    "        model.hidden = model.init_hidden()\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        y_pred = model(batch_X)\n",
    "        # compute loss\n",
    "        loss = loss_fxn(y_pred, batch_y)\n",
    "        # back propogation\n",
    "        loss.backwards()\n",
    "        # update gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "if epoch % 10 == 0:\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} -> loss: {np.mean(losses):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
